# Aetheris Oracle - Environment Configuration Example
# Copy this file to .env and configure as needed

# ============================================================
# EXTERNAL API KEYS (Optional - Currently Not Required)
# ============================================================
# The app uses public/free APIs that don't require authentication:
# - ccxt (Binance public OHLCV data)
# - Deribit public volatility index
# - yfinance (Yahoo Finance macro data)
#
# If you upgrade to premium APIs or private endpoints, configure here:
# BINANCE_API_KEY=your_binance_api_key_here
# BINANCE_API_SECRET=your_binance_secret_here
# DERIBIT_API_KEY=your_deribit_api_key_here
# DERIBIT_API_SECRET=your_deribit_secret_here

# ============================================================
# INTERNAL SERVICE AUTHENTICATION (Optional)
# ============================================================
# Protect the FastAPI /forecast endpoint with an API key
# If set, clients must send "x-api-key: <value>" header
AETHERIS_API_KEY=

# Example usage:
# AETHERIS_API_KEY=my-secret-key-12345

# ============================================================
# PYTORCH / CUDA CONFIGURATION
# ============================================================
# Device for neural model inference ("cpu", "cuda", "cuda:0", etc.)
TORCH_DEVICE=cpu

# Enable CUDA optimizations
# CUDA_LAUNCH_BLOCKING=0

# ============================================================
# MODEL ARTIFACT PATHS
# ============================================================
# Override default artifact locations for pretrained SOTA models
# ARTIFACT_ROOT=./artifacts
# NCC_ARTIFACT_PATH=./artifacts/ncc_state.pt
# FMGP_ARTIFACT_PATH=./artifacts/fm_gp_state.pt
# NEURAL_JUMP_ARTIFACT_PATH=./artifacts/neural_jump_sde_state.pt
# DIFF_GREEKS_ARTIFACT_PATH=./artifacts/diff_greeks_state.pt
# NEURAL_VOL_ARTIFACT_PATH=./artifacts/neural_rough_vol_state.pt
# MAMBA_ARTIFACT_PATH=./artifacts/mamba_trend_state.pt

# ============================================================
# CALIBRATION PERSISTENCE
# ============================================================
# Path to save/load calibration state
# CALIBRATION_PATH=./calibration.json

# ============================================================
# LOGGING & MONITORING
# ============================================================
# Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# Enable performance metrics logging
METRICS_ENABLED=true

# ============================================================
# EXPERIMENT TRACKING (Optional)
# ============================================================
# Weights & Biases
# WANDB_API_KEY=your_wandb_api_key_here
# WANDB_PROJECT=aetheris-oracle
# WANDB_ENTITY=your_wandb_username

# MLflow
# MLFLOW_TRACKING_URI=http://localhost:5000
# MLFLOW_EXPERIMENT_NAME=aetheris-forecasting

# ============================================================
# SERVICE CONFIGURATION
# ============================================================
# FastAPI server settings
# HOST=0.0.0.0
# PORT=8000
# RELOAD=false

# CORS allowed origins (comma-separated)
# CORS_ORIGINS=http://localhost:3000,https://yourdomain.com

# ============================================================
# FEATURE FLAGS
# ============================================================
# Enable SOTA components (true/false)
USE_NCC_CALIBRATION=false
USE_FM_GP_RESIDUALS=false
USE_NEURAL_JUMPS=false
USE_DIFF_GREEKS=false
USE_NEURAL_ROUGH_VOL=false
USE_MAMBA_TREND=false
USE_INTEGRATED_GRADIENTS=false
USE_IMPORTANCE_SAMPLING=true

# ============================================================
# TRAINING DATA CONFIGURATION
# ============================================================
# Historical data lookback period (days) for training SOTA models
# Default: 180 days (production quality: ~20-30 min)
# Options: 30 (1 month - fast but insufficient data),
#          90 (3 months - development/testing),
#          180 (6 months - production recommended),
#          365 (1 year - best quality, very slow)
TRAINING_LOOKBACK_DAYS=180

# Number of training samples to generate per component
# Default: 300 (production quality)
# Options: 50 (prototype), 150 (development), 300 (production), 500+ (research)
TRAINING_SAMPLES_NCC=300
TRAINING_SAMPLES_FMGP=300
TRAINING_SAMPLES_NEURAL_JUMP=300
TRAINING_SAMPLES_DIFF_GREEKS=200
TRAINING_SAMPLES_NEURAL_VOL=300
TRAINING_SAMPLES_MAMBA=300

# Training window size (days of historical data per sample)
# Default: 90 days (3 months of context per sample)
TRAINING_WINDOW_DAYS=90
