# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

**Aetheris Oracle v10.0** - A probabilistic N-day price forecasting engine for crypto assets (BTC-USD, ETH-USD). Produces forecast cones (quantile paths P5-P95) over 1-90 day horizons, designed to be robust across market regimes.

The system supports two model families:
- **Legacy**: Heuristic models (fast, production-ready, but overconfident ~5% spread)
- **5-SOTA (Recommended)**: 5-component neural stack trained on historical data
  - Realistic ~33% spread for 7-day forecasts
  - Supports 7, 30, and 90-day horizons
  - Excludes MambaTS trend due to directional bias issues

For detailed documentation:
- [README.md](README.md) - Quick start, TODO checklist, known issues
- [docs/implementation/PROJECT_STATUS.md](docs/implementation/PROJECT_STATUS.md) - Implementation status
- [docs/design/plan.md](docs/design/plan.md) - System design specification

## Quick Start

All config is in `.env` - copy from `.env.example` and edit as needed.

### 1. Setup
```bash
python -m venv .venv
.venv\Scripts\python -m pip install -r requirements.txt
copy .env.example .env   # Windows
cp .env.example .env     # Linux/Mac

# Optional: ast-grep for code search/refactoring (already installed)
# npm install -g @ast-grep/cli
```

### 2. Hyperparameter Tuning (optional)
```bash
# Quick tuning (recommended before training)
.venv\Scripts\python scripts/hyperparameter_tuning.py --component all --quick -w 8

# Standard tuning (more thorough)
.venv\Scripts\python scripts/hyperparameter_tuning.py --component all -w 4

# Single component
.venv\Scripts\python scripts/hyperparameter_tuning.py --component fmgp --quick
```

### 3. Train
```bash
.venv\Scripts\python train.py           # Full training (uses tuned hyperparameters from .env)
.venv\Scripts\python train.py --quick   # Quick training
.venv\Scripts\python train.py -w 4      # Parallel training with 4 workers
```

### 4. Run Forecasts
```bash
.venv\Scripts\python run.py             # Uses .env config
.venv\Scripts\python run.py --legacy    # Use legacy models
```

## Key .env Settings

### Forecast Configuration
```bash
FORECAST_ASSET=BTC-USD      # Asset to forecast
FORECAST_HORIZON=30         # Days ahead (7, 30, 90)
FORECAST_PATHS=1000         # Monte Carlo paths
```

### Training Configuration
```bash
TRAINING_HORIZON=30              # Horizon to train for
TRAINING_LOOKBACK_DAYS=1825      # Historical data window (~5 years)
TRAINING_HOLDOUT_DAYS=30         # Recent data excluded from training
TRAINING_SAMPLES_NCC=500         # Training samples per component
TRAINING_SAMPLES_FMGP=500
TRAINING_SAMPLES_NEURAL_JUMP=500
TRAINING_SAMPLES_DIFF_GREEKS=400
TRAINING_SAMPLES_NEURAL_VOL=500
```

### Model Selection (5-SOTA Recommended)
```bash
USE_NCC_CALIBRATION=true
USE_FM_GP_RESIDUALS=true
USE_NEURAL_JUMPS=true
USE_DIFF_GREEKS=true
USE_NEURAL_ROUGH_VOL=true
USE_MAMBA_TREND=false       # Keep false - has bias issues
```

### Tuned Hyperparameters (auto-generated by hyperparameter_tuning.py)
```bash
# These are automatically updated by hyperparameter tuning
TUNING_NCC_LR=0.001000
TUNING_NCC_EPOCHS=25
TUNING_FMGP_LR=0.000500
TUNING_FMGP_EPOCHS=50
# ... etc
```

## Architecture

### Core Data Flow

```
DataConnector.fetch_window() → MarketFeatureFrame
       ↓
StationarityNormalizer.normalize_and_stats() → normalized closes + stats
       ↓
compute_regime_vector() → RegimeVector (conditioning for all models)
       ↓
┌─────────────────────────────────────────────────────────────┐
│ Model Pipeline (legacy or SOTA based on feature flags)      │
├─────────────────────────────────────────────────────────────┤
│ MarketMakerEngine / DifferentiableMMEngine → MM indices     │
│ VolPathEngine / NeuralRoughVolWrapper → VolPath             │
│ ResidualGenerator / FMGPResidualEngine → ResidualPaths      │
│ JumpModel / NeuralJumpSDEEngine → JumpPath                  │
└─────────────────────────────────────────────────────────────┘
       ↓
Path Assembly: trend + jumps + residuals → price paths (denormalized)
       ↓
CalibrationEngine / NCCCalibrationEngine → adjusted quantiles
       ↓
ForecastResult: quantile_paths, threshold_probs, drivers, metadata
```

### Key Source Locations

| Component | Legacy | SOTA |
|-----------|--------|------|
| Volatility | `modules/vol_path.py` | `modules/neural_rough_vol.py` |
| Jumps | `modules/jump.py` | `modules/neural_jump_sde.py` |
| Residuals | `modules/residual.py` | `modules/fm_gp_residual.py` |
| MM State | `modules/market_maker.py` | `modules/differentiable_greeks.py` |
| Calibration | `pipeline/calibration.py` | `pipeline/neural_conformal_control.py` |
| Orchestration | `pipeline/forecast.py` (ForecastEngine) |
| Training | `pipeline/train_sota.py`, `pipeline/training_data_prep.py` |

### Data Connectors

- `SyntheticDataConnector` - Deterministic data for tests
- `FreeDataConnector` - ccxt + Deribit + yfinance (no API keys, free)
- `HistoricalParquetConnector` - Local parquet files (for training)
- `CCXTPerpConnector` - Spot + perp with caching

## Training Pipeline

### Hyperparameter Tuning
- **Parallel processing**: Use `-w` flag to run trials in parallel
- **Data fetching**: Single API call with local slicing (no 180 individual calls)
- **Validation split**: 80/20 train/validation to prevent overfitting
- **NaN handling**: Robust numerical stability in neural_rough_vol

### Regular Training
- **Parallel training**: Base components (fmgp, neural_jump, neural_vol, diff_greeks) train in parallel
- **NCC runs last**: Depends on other models being trained first
- **Uses tuned hyperparameters**: Reads TUNING_* env vars from .env

### Holdout Period
- **Purpose**: Prevents temporal overfitting by excluding recent data
- **Default**: 2x forecast horizon, clamped 60-90 days (or TRAINING_HOLDOUT_DAYS from .env)
- **Recommendation**: 30 days for 30-day forecasts (balance recency vs. overfitting)

## Development Tools

- **ast-grep skill**: Structural code search and refactoring (installed via Claude Code marketplace)
  - Use `/ast-grep` skill for AST-based code searches and transformations
  - CLI also available: `ast-grep --pattern 'def $FUNC($$$)' --lang python`
  - Interactive: `sg scan` for codebase-wide searches

## Design Constraints

- **Zero-mean residuals**: Residual paths must have zero mean over horizon to avoid double-counting trend
- **Past-only normalization**: No look-ahead bias in `StationarityNormalizer`
- **Regime conditioning**: All models receive `RegimeVector` as input
- **Reproducibility**: All random seeds should be configurable
- **Numerical stability**: NaN/inf handling in neural_rough_vol forward pass and training

## Known Issues & Resolutions

### Resolved (2025-11-26)
1. **NCC training mismatch** - Fixed: NCC now trained on SOTA forecasts
2. **yfinance data bug** - Fixed: use `start/end` not `period`
3. **Mamba directional bias** - UNFIXABLE: removed from recommended config

### Resolved (2025-11-29)
4. **Hyperparameter tuning errors** - Fixed: sample_sde_paths signature, tensor mismatches
5. **Neural_rough_vol NaN issues** - Fixed: Added numerical stability (clamping, NaN handling)
6. **API rate limiting** - Fixed: Single API call + prefetching for parallel workers

**Recommendation**: Use 5-component SOTA (without Mamba) for best results.

## Feature Flags

### Recommended: 5-Component SOTA
```python
engine = ForecastEngine(
    use_ncc_calibration=True,
    use_diff_greeks=True,
    use_fm_gp_residuals=True,
    use_neural_rough_vol=True,
    use_neural_jumps=True,
    use_mamba_trend=False,  # Exclude - has directional bias issues
    device="cpu",  # or "cuda"
)
```

### Legacy (fast but overconfident)
```python
engine = ForecastEngine()  # All SOTA flags default to False
```

Models are loaded from `artifacts/` directory.
